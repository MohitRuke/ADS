{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C - PREDICTION OF CANCER SURVIVAL\n",
    "\n",
    "Dataset : Wisconsin Prognostic Breast Cancer Dataset\n",
    "\n",
    "Glossary:\n",
    "This file contains patients' nuclear features, survival time and chemotherapy \n",
    "information.  The 39 columns contain the following information:\n",
    "\n",
    "* Patient's artificially created number i=1,......,253.\n",
    "* 2.  code_a = 0 if non-recur\n",
    "             = 1 if recur\n",
    "* 3.  code_b = 0 if death is not caused by cancer or person leaves the group\n",
    "\t\t     = 1 if death is caused by cancer\n",
    "* 4.  time_a = time (months) DFS/TTR \n",
    "\t\t       DFS : Disease Free Survival (code a=0)\n",
    "         \t   TTR : Time To Recur (if code a=1)\n",
    "* 5.  time_b = survival time (months) for patients who die, leave or survive the total time of the study 158 months at December 1997.\n",
    "* 6.  radius\n",
    "* 7.  texture\n",
    "* 8.  perimeter\n",
    "* 9.  area\n",
    "* 10.  smoothness\n",
    "* 11.  compactness\n",
    "* 12.  concavity\n",
    "* 13.  concave point\n",
    "* 14.  symmetry\n",
    "* 15.  fractal dimension\n",
    "* 16. to 25. Standard devisation of 6. to 15. above\n",
    "* 26. to 35. Largest (worst) of 6. to 15. above\n",
    "* 36.  tumor size\n",
    "* 37.  Q(i, 36) = Lymph node status \n",
    "\t  (number of metastasized lymph nodes: 0 to 30)\n",
    "* 38.   hormo = 1 if patient received first chemotherapy\n",
    "\t\t\t  = 0 otherwise\n",
    "* 39.   chemo = 1 if patient received second chemotherapy\n",
    "\t\t\t  = 0 otherwise\n",
    "\n",
    "The text in the document by Gauresh Chavan, Kaushal Chaudhary and Mohit Ruke is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/\n",
    "\n",
    "The code in the document by Gauresh Chavan, Kaushal Chaudhary and Mohit Ruke is licensed under the MIT License https://opensource.org/licenses/MIT\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing packages**\n",
    "Credits:[Randal Olson TPOT](http://www.randalolson.com/2015/11/15/introducing-tpot-the-data-science-assistant/)\n",
    "\n",
    "TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.\n",
    "TPOT will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for our data.Once TPOT is finished searching, it provides us with the Python code for the best pipeline it found so you can tinker with the pipeline from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boruta\n",
      "  Downloading https://files.pythonhosted.org/packages/35/03/ca2b7e352bf1f0e2dd0e17e1b8c92f75dbb9f218d36eba4e894efa2a0478/Boruta-0.1.5.tar.gz (55kB)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from boruta)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from boruta)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from boruta)\n",
      "Building wheels for collected packages: boruta\n",
      "  Running setup.py bdist_wheel for boruta: started\n",
      "  Running setup.py bdist_wheel for boruta: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\rukem\\AppData\\Local\\pip\\Cache\\wheels\\5c\\5a\\72\\13e8ea10ba10e22e9ca7f76f8b451c9f98fa190d428c8857dd\n",
      "Successfully built boruta\n",
      "Installing collected packages: boruta\n",
      "Successfully installed boruta-0.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/e6/a41be0ddb23a411dc78b92f6a90b8129e65856a8248f8f11b2f14d8eeee3/TPOT-0.9.3.tar.gz (888kB)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from tpot)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from tpot)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from tpot)\n",
      "Collecting deap>=1.0 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/af/29/e7f2ecbe02997b16a768baed076f5fc4781d7057cd5d9adf7c94027845ba/deap-1.2.2.tar.gz (936kB)\n",
      "Collecting update_checker>=0.16 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.11.2 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from tpot)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
      "Requirement already satisfied: pandas>=0.20.2 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from tpot)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: python-dateutil>=2 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from pandas>=0.20.2->tpot)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from pandas>=0.20.2->tpot)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rukem\\anaconda3\\lib\\site-packages (from python-dateutil>=2->pandas>=0.20.2->tpot)\n",
      "Building wheels for collected packages: tpot, deap, stopit\n",
      "  Running setup.py bdist_wheel for tpot: started\n",
      "  Running setup.py bdist_wheel for tpot: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\rukem\\AppData\\Local\\pip\\Cache\\wheels\\00\\f3\\4d\\8d28f69c59669ba720eebaa4ebc8a3b28da2a61662367b38e8\n",
      "  Running setup.py bdist_wheel for deap: started\n",
      "  Running setup.py bdist_wheel for deap: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\rukem\\AppData\\Local\\pip\\Cache\\wheels\\22\\ea\\bf\\dc7c8a2262025a0ab5da9ef02282c198be88902791ca0c6658\n",
      "  Running setup.py bdist_wheel for stopit: started\n",
      "  Running setup.py bdist_wheel for stopit: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\rukem\\AppData\\Local\\pip\\Cache\\wheels\\3c\\85\\2b\\2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
      "Successfully built tpot deap stopit\n",
      "Installing collected packages: deap, update-checker, stopit, tpot\n",
      "Successfully installed deap-1.2.2 stopit-1.1.2 tpot-0.9.3 update-checker-0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install boruta\n",
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>CODE_A</th>\n",
       "      <th>CODE_B</th>\n",
       "      <th>TIME_A</th>\n",
       "      <th>TIME_B</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>TEXTURE</th>\n",
       "      <th>PERIMETR</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SMOOTH</th>\n",
       "      <th>...</th>\n",
       "      <th>WSMOOTH</th>\n",
       "      <th>WCOMPCT</th>\n",
       "      <th>WCONCV</th>\n",
       "      <th>WCONV_PT</th>\n",
       "      <th>WSYMM</th>\n",
       "      <th>WFRACT_D</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>NODE_ALL</th>\n",
       "      <th>CHEMO</th>\n",
       "      <th>HORMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>27.70</td>\n",
       "      <td>96.01</td>\n",
       "      <td>604.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.11830</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>13.32</td>\n",
       "      <td>27.25</td>\n",
       "      <td>85.99</td>\n",
       "      <td>551.7</td>\n",
       "      <td>0.08446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.3018</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.08557</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>15.11</td>\n",
       "      <td>32.79</td>\n",
       "      <td>99.36</td>\n",
       "      <td>712.3</td>\n",
       "      <td>0.09656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>13.99</td>\n",
       "      <td>36.52</td>\n",
       "      <td>92.27</td>\n",
       "      <td>598.3</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.09596</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.07969</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATIENT  CODE_A  CODE_B  TIME_A  TIME_B  RADIUS  TEXTURE  PERIMETR    AREA  \\\n",
       "0        1       0       0      55      55   18.02    27.60    117.50  1013.0   \n",
       "1        2       0       0      29      29   14.09    27.70     96.01   604.7   \n",
       "2        3       0       0      53      53   13.32    27.25     85.99   551.7   \n",
       "3        4       1       0      12      68   15.11    32.79     99.36   712.3   \n",
       "4        5       0       0      56      56   13.99    36.52     92.27   598.3   \n",
       "\n",
       "    SMOOTH  ...    WSMOOTH  WCOMPCT  WCONCV  WCONV_PT   WSYMM  WFRACT_D  SIZE  \\\n",
       "0  0.09489  ...     0.1195   0.1926  0.3140   0.11700  0.2677   0.08113   5.0   \n",
       "1  0.11860  ...     0.1555   0.5988  0.7392   0.18710  0.2497   0.11830   0.8   \n",
       "2  0.08446  ...     0.1197   0.3018  0.3039   0.11670  0.2859   0.08557   1.3   \n",
       "3  0.09656  ...     0.1408   0.4667  0.6024   0.12780  0.2773   0.10450   2.5   \n",
       "4  0.11780  ...     0.1613   0.2520  0.3125   0.09596  0.2154   0.07969   0.8   \n",
       "\n",
       "   NODE_ALL  CHEMO  HORMO  \n",
       "0         5      1      1  \n",
       "1         0      0      0  \n",
       "2         0      0      0  \n",
       "3         0      0      0  \n",
       "4         1      0      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the dataset\n",
    "dataset = pd.read_csv(\"WPBCC.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>CODE_B</th>\n",
       "      <th>CODE_A</th>\n",
       "      <th>TIME_A</th>\n",
       "      <th>TIME_B</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>TEXTURE</th>\n",
       "      <th>PERIMETR</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SMOOTH</th>\n",
       "      <th>...</th>\n",
       "      <th>WSMOOTH</th>\n",
       "      <th>WCOMPCT</th>\n",
       "      <th>WCONCV</th>\n",
       "      <th>WCONV_PT</th>\n",
       "      <th>WSYMM</th>\n",
       "      <th>WFRACT_D</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>NODE_ALL</th>\n",
       "      <th>CHEMO</th>\n",
       "      <th>HORMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>27.70</td>\n",
       "      <td>96.01</td>\n",
       "      <td>604.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.11830</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>13.32</td>\n",
       "      <td>27.25</td>\n",
       "      <td>85.99</td>\n",
       "      <td>551.7</td>\n",
       "      <td>0.08446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.3018</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.08557</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>15.11</td>\n",
       "      <td>32.79</td>\n",
       "      <td>99.36</td>\n",
       "      <td>712.3</td>\n",
       "      <td>0.09656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>13.99</td>\n",
       "      <td>36.52</td>\n",
       "      <td>92.27</td>\n",
       "      <td>598.3</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.09596</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.07969</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATIENT  CODE_B  CODE_A  TIME_A  TIME_B  RADIUS  TEXTURE  PERIMETR    AREA  \\\n",
       "0        1       0       0      55      55   18.02    27.60    117.50  1013.0   \n",
       "1        2       0       0      29      29   14.09    27.70     96.01   604.7   \n",
       "2        3       0       0      53      53   13.32    27.25     85.99   551.7   \n",
       "3        4       0       1      12      68   15.11    32.79     99.36   712.3   \n",
       "4        5       0       0      56      56   13.99    36.52     92.27   598.3   \n",
       "\n",
       "    SMOOTH  ...    WSMOOTH  WCOMPCT  WCONCV  WCONV_PT   WSYMM  WFRACT_D  SIZE  \\\n",
       "0  0.09489  ...     0.1195   0.1926  0.3140   0.11700  0.2677   0.08113   5.0   \n",
       "1  0.11860  ...     0.1555   0.5988  0.7392   0.18710  0.2497   0.11830   0.8   \n",
       "2  0.08446  ...     0.1197   0.3018  0.3039   0.11670  0.2859   0.08557   1.3   \n",
       "3  0.09656  ...     0.1408   0.4667  0.6024   0.12780  0.2773   0.10450   2.5   \n",
       "4  0.11780  ...     0.1613   0.2520  0.3125   0.09596  0.2154   0.07969   0.8   \n",
       "\n",
       "   NODE_ALL  CHEMO  HORMO  \n",
       "0         5      1      1  \n",
       "1         0      0      0  \n",
       "2         0      0      0  \n",
       "3         0      0      0  \n",
       "4         1      0      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[['PATIENT','CODE_B', 'CODE_A', 'TIME_A', 'TIME_B', 'RADIUS', 'TEXTURE',\n",
    "       'PERIMETR', 'AREA', 'SMOOTH', 'COMPCT', 'CONCV', 'CONV_PT', 'SYMM',\n",
    "       'FRACT_D', 'SRADIUS', 'STEXTURE', 'SPERIMET', 'SAREA', 'SSMOOTH',\n",
    "       'SCOMPCT', 'SCONCV', 'SCONV_PT', 'SSYMM', 'SFRACT_D', 'WRADIUS',\n",
    "       'WTEXTURE', 'WPERIMET', 'WAREA', 'WSMOOTH', 'WCOMPCT', 'WCONCV',\n",
    "       'WCONV_PT', 'WSYMM', 'WFRACT_D', 'SIZE', 'NODE_ALL', 'CHEMO', 'HORMO']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_A</th>\n",
       "      <th>TIME_A</th>\n",
       "      <th>TIME_B</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>TEXTURE</th>\n",
       "      <th>PERIMETR</th>\n",
       "      <th>AREA</th>\n",
       "      <th>SMOOTH</th>\n",
       "      <th>COMPCT</th>\n",
       "      <th>CONCV</th>\n",
       "      <th>...</th>\n",
       "      <th>WSMOOTH</th>\n",
       "      <th>WCOMPCT</th>\n",
       "      <th>WCONCV</th>\n",
       "      <th>WCONV_PT</th>\n",
       "      <th>WSYMM</th>\n",
       "      <th>WFRACT_D</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>NODE_ALL</th>\n",
       "      <th>CHEMO</th>\n",
       "      <th>HORMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>27.70</td>\n",
       "      <td>96.01</td>\n",
       "      <td>604.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.25530</td>\n",
       "      <td>0.24860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.11830</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>13.32</td>\n",
       "      <td>27.25</td>\n",
       "      <td>85.99</td>\n",
       "      <td>551.7</td>\n",
       "      <td>0.08446</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.05168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.3018</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.08557</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>15.11</td>\n",
       "      <td>32.79</td>\n",
       "      <td>99.36</td>\n",
       "      <td>712.3</td>\n",
       "      <td>0.09656</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>13.99</td>\n",
       "      <td>36.52</td>\n",
       "      <td>92.27</td>\n",
       "      <td>598.3</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.14060</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.09596</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.07969</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODE_A  TIME_A  TIME_B  RADIUS  TEXTURE  PERIMETR    AREA   SMOOTH  \\\n",
       "0       0      55      55   18.02    27.60    117.50  1013.0  0.09489   \n",
       "1       0      29      29   14.09    27.70     96.01   604.7  0.11860   \n",
       "2       0      53      53   13.32    27.25     85.99   551.7  0.08446   \n",
       "3       1      12      68   15.11    32.79     99.36   712.3  0.09656   \n",
       "4       0      56      56   13.99    36.52     92.27   598.3  0.11780   \n",
       "\n",
       "    COMPCT    CONCV  ...    WSMOOTH  WCOMPCT  WCONCV  WCONV_PT   WSYMM  \\\n",
       "0  0.10360  0.10860  ...     0.1195   0.1926  0.3140   0.11700  0.2677   \n",
       "1  0.25530  0.24860  ...     0.1555   0.5988  0.7392   0.18710  0.2497   \n",
       "2  0.07879  0.05168  ...     0.1197   0.3018  0.3039   0.11670  0.2859   \n",
       "3  0.12230  0.13380  ...     0.1408   0.4667  0.6024   0.12780  0.2773   \n",
       "4  0.14060  0.10720  ...     0.1613   0.2520  0.3125   0.09596  0.2154   \n",
       "\n",
       "   WFRACT_D  SIZE  NODE_ALL  CHEMO  HORMO  \n",
       "0   0.08113   5.0         5      1      1  \n",
       "1   0.11830   0.8         0      0      0  \n",
       "2   0.08557   1.3         0      0      0  \n",
       "3   0.10450   2.5         0      0      0  \n",
       "4   0.07969   0.8         1      0      1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X are the varibles used for predictions Y is the target\n",
    "X = data.drop(['PATIENT','CODE_B'],axis=1)\n",
    "Y = data['CODE_B']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PATIENT     0\n",
       "CODE_B      0\n",
       "CODE_A      0\n",
       "TIME_A      0\n",
       "TIME_B      0\n",
       "RADIUS      0\n",
       "TEXTURE     0\n",
       "PERIMETR    0\n",
       "AREA        0\n",
       "SMOOTH      0\n",
       "COMPCT      0\n",
       "CONCV       0\n",
       "CONV_PT     0\n",
       "SYMM        0\n",
       "FRACT_D     0\n",
       "SRADIUS     0\n",
       "STEXTURE    0\n",
       "SPERIMET    0\n",
       "SAREA       0\n",
       "SSMOOTH     0\n",
       "SCOMPCT     0\n",
       "SCONCV      0\n",
       "SCONV_PT    0\n",
       "SSYMM       0\n",
       "SFRACT_D    0\n",
       "WRADIUS     0\n",
       "WTEXTURE    0\n",
       "WPERIMET    0\n",
       "WAREA       0\n",
       "WSMOOTH     0\n",
       "WCOMPCT     0\n",
       "WCONCV      0\n",
       "WCONV_PT    0\n",
       "WSYMM       0\n",
       "WFRACT_D    0\n",
       "SIZE        0\n",
       "NODE_ALL    0\n",
       "CHEMO       0\n",
       "HORMO       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 39 columns):\n",
      "PATIENT     253 non-null int64\n",
      "CODE_B      253 non-null int64\n",
      "CODE_A      253 non-null int64\n",
      "TIME_A      253 non-null int64\n",
      "TIME_B      253 non-null int64\n",
      "RADIUS      253 non-null float64\n",
      "TEXTURE     253 non-null float64\n",
      "PERIMETR    253 non-null float64\n",
      "AREA        253 non-null float64\n",
      "SMOOTH      253 non-null float64\n",
      "COMPCT      253 non-null float64\n",
      "CONCV       253 non-null float64\n",
      "CONV_PT     253 non-null float64\n",
      "SYMM        253 non-null float64\n",
      "FRACT_D     253 non-null float64\n",
      "SRADIUS     253 non-null float64\n",
      "STEXTURE    253 non-null float64\n",
      "SPERIMET    253 non-null float64\n",
      "SAREA       253 non-null float64\n",
      "SSMOOTH     253 non-null float64\n",
      "SCOMPCT     253 non-null float64\n",
      "SCONCV      253 non-null float64\n",
      "SCONV_PT    253 non-null float64\n",
      "SSYMM       253 non-null float64\n",
      "SFRACT_D    253 non-null float64\n",
      "WRADIUS     253 non-null float64\n",
      "WTEXTURE    253 non-null float64\n",
      "WPERIMET    253 non-null float64\n",
      "WAREA       253 non-null float64\n",
      "WSMOOTH     253 non-null float64\n",
      "WCOMPCT     253 non-null float64\n",
      "WCONCV      253 non-null float64\n",
      "WCONV_PT    253 non-null float64\n",
      "WSYMM       253 non-null float64\n",
      "WFRACT_D    253 non-null float64\n",
      "SIZE        253 non-null float64\n",
      "NODE_ALL    253 non-null int64\n",
      "CHEMO       253 non-null int64\n",
      "HORMO       253 non-null int64\n",
      "dtypes: float64(31), int64(8)\n",
      "memory usage: 77.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fitting the data in random forest algorithm by splitting it into training and testing dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=np.random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7 - Current best internal CV score: 0.9503658536585367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8 - Current best internal CV score: 0.9551219512195122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 9 - Current best internal CV score: 0.9551219512195122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 - Current best internal CV score: 0.9551219512195122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: ExtraTreesClassifier(LogisticRegression(MaxAbsScaler(input_matrix), C=1.0, dual=False, penalty=l2), bootstrap=True, criterion=gini, max_features=0.75, min_samples_leaf=1, min_samples_split=13, n_estimators=100)\n",
      "0.803921568627\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=10, population_size=50, verbosity=2)\n",
    "tpot.fit(X_train, Y_train)\n",
    "print(tpot.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr = ExtraTreesClassifier()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=np.random)\n",
    "etr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 1.000\n",
      "Accuracy on the test subset: 0.882\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the training subset: {:.3f}'.format(etr.score(X_train, Y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(etr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = etr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 5  3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144    0\n",
       "184    1\n",
       "251    0\n",
       "129    1\n",
       "127    0\n",
       "137    0\n",
       "69     0\n",
       "132    0\n",
       "187    0\n",
       "181    0\n",
       "128    1\n",
       "225    0\n",
       "31     0\n",
       "27     1\n",
       "215    0\n",
       "13     0\n",
       "54     0\n",
       "74     0\n",
       "76     0\n",
       "11     0\n",
       "179    0\n",
       "180    1\n",
       "185    0\n",
       "75     1\n",
       "155    1\n",
       "221    0\n",
       "134    0\n",
       "38     0\n",
       "25     0\n",
       "234    0\n",
       "211    0\n",
       "164    0\n",
       "62     0\n",
       "232    0\n",
       "209    0\n",
       "55     1\n",
       "233    0\n",
       "35     0\n",
       "219    0\n",
       "99     0\n",
       "252    0\n",
       "145    0\n",
       "202    0\n",
       "142    0\n",
       "77     0\n",
       "192    0\n",
       "200    0\n",
       "207    0\n",
       "246    0\n",
       "59     0\n",
       "53     0\n",
       "Name: CODE_B, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum per feature\n",
      "CODE_A      0.0\n",
      "TIME_A      0.0\n",
      "TIME_B      0.0\n",
      "RADIUS      0.0\n",
      "TEXTURE     0.0\n",
      "PERIMETR    0.0\n",
      "AREA        0.0\n",
      "SMOOTH      0.0\n",
      "COMPCT      0.0\n",
      "CONCV       0.0\n",
      "CONV_PT     0.0\n",
      "SYMM        0.0\n",
      "FRACT_D     0.0\n",
      "SRADIUS     0.0\n",
      "STEXTURE    0.0\n",
      "SPERIMET    0.0\n",
      "SAREA       0.0\n",
      "SSMOOTH     0.0\n",
      "SCOMPCT     0.0\n",
      "SCONCV      0.0\n",
      "SCONV_PT    0.0\n",
      "SSYMM       0.0\n",
      "SFRACT_D    0.0\n",
      "WRADIUS     0.0\n",
      "WTEXTURE    0.0\n",
      "WPERIMET    0.0\n",
      "WAREA       0.0\n",
      "WSMOOTH     0.0\n",
      "WCOMPCT     0.0\n",
      "WCONCV      0.0\n",
      "WCONV_PT    0.0\n",
      "WSYMM       0.0\n",
      "WFRACT_D    0.0\n",
      "SIZE        0.0\n",
      "NODE_ALL    0.0\n",
      "CHEMO       0.0\n",
      "HORMO       0.0\n",
      "dtype: float64\n",
      "Maximum per feature\n",
      "CODE_A      1.0\n",
      "TIME_A      1.0\n",
      "TIME_B      1.0\n",
      "RADIUS      1.0\n",
      "TEXTURE     1.0\n",
      "PERIMETR    1.0\n",
      "AREA        1.0\n",
      "SMOOTH      1.0\n",
      "COMPCT      1.0\n",
      "CONCV       1.0\n",
      "CONV_PT     1.0\n",
      "SYMM        1.0\n",
      "FRACT_D     1.0\n",
      "SRADIUS     1.0\n",
      "STEXTURE    1.0\n",
      "SPERIMET    1.0\n",
      "SAREA       1.0\n",
      "SSMOOTH     1.0\n",
      "SCOMPCT     1.0\n",
      "SCONCV      1.0\n",
      "SCONV_PT    1.0\n",
      "SSYMM       1.0\n",
      "SFRACT_D    1.0\n",
      "WRADIUS     1.0\n",
      "WTEXTURE    1.0\n",
      "WPERIMET    1.0\n",
      "WAREA       1.0\n",
      "WSMOOTH     1.0\n",
      "WCOMPCT     1.0\n",
      "WCONCV      1.0\n",
      "WCONV_PT    1.0\n",
      "WSYMM       1.0\n",
      "WFRACT_D    1.0\n",
      "SIZE        1.0\n",
      "NODE_ALL    1.0\n",
      "CHEMO       1.0\n",
      "HORMO       1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Finding the minimum values for each feature\n",
    "min_train = X_train.min(axis=0)\n",
    "#Finding the range of each feature\n",
    "range_train = (X_train - min_train).max(axis=0)\n",
    "#Scaling the features between the the range 0 to 1 \n",
    "X_train_scaled = (X_train - min_train)/range_train\n",
    "\n",
    "print('Minimum per feature\\n{}'.format(X_train_scaled.min(axis=0)))\n",
    "print('Maximum per feature\\n{}'.format(X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaled = (X_test - min_train)/range_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Tree (Extra) Tree Classifier:\n",
    "\n",
    "This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. More about [Extra tree Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr1 = ExtraTreesClassifier()\n",
    "etr1.fit(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the training subset: 1.000\n",
      "The accuracy on the test subset: 0.863\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy on the training subset: {:.3f}'.format(etr1.score(X_train_scaled, Y_train)))\n",
    "print('The accuracy on the test subset: {:.3f}'.format(etr1.score(X_test_scaled, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_prediction = etr1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 6  2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,s_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we're facing overfitting problem. To avoid this, we perform feature engineering to select only important features that contribute towards prediction. More about [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "  n_features_to_select=10, step=1, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFE(etr, n_features_to_select=10)\n",
    "rfe.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1, 28, 23, 19,  3, 17, 12, 10, 18, 25, 27, 13,\n",
       "       26,  7,  8, 14,  5, 21, 20, 11, 22,  1, 15,  6,  9,  4,  1, 16,  1,\n",
       "        2,  1, 24])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False,  True, False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'], \n",
    "              'criterion': ['gini','entropy'], 'n_estimators':[1,5,10,15,20] } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(ExtraTreesClassifier(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=1, score=0.9117647058823529, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=gini, max_features=auto, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=1, score=0.8970588235294118, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] criterion=gini, max_features=auto, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=1, score=0.8333333333333334, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=5, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=5, score=0.8382352941176471, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=5, score=0.8333333333333334, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=10, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=10, score=0.8529411764705882, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=10, score=0.8484848484848485, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=15, score=0.9411764705882353, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=15, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=15, score=0.8636363636363636, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=20, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=20, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=auto, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=auto, n_estimators=20, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=1, score=0.7941176470588235, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=1, score=0.8382352941176471, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=1, score=0.9242424242424242, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=5, score=0.8529411764705882, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=5, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=5, score=0.7878787878787878, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=10, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=10, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=10, score=0.8939393939393939, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=15, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=15, score=0.9411764705882353, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=15, score=0.9242424242424242, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=20, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=20, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=gini, max_features=sqrt, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=sqrt, n_estimators=20, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=1, score=0.7794117647058824, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=1, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=1 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=1, score=0.7424242424242424, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=5, score=0.9558823529411765, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=5, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=5 ...............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=5, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=10, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=10, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=10 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=10, score=0.8939393939393939, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=15, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=15, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=15 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=15, score=0.8484848484848485, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=20, score=0.9411764705882353, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=20, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=gini, max_features=log2, n_estimators=20 ..............\n",
      "[CV]  criterion=gini, max_features=log2, n_estimators=20, score=0.8636363636363636, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=1, score=0.8529411764705882, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=1, score=0.8235294117647058, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=1, score=0.9090909090909091, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=5, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=5, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=5 ............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_features=auto, n_estimators=5, score=0.9090909090909091, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=10, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=10, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=10, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=15, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=15, score=0.8235294117647058, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=15, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=20, score=0.9558823529411765, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=20, score=0.8676470588235294, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=auto, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=auto, n_estimators=20, score=0.8939393939393939, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=1, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=1, score=0.8676470588235294, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=1, score=0.8484848484848485, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=5, score=0.8676470588235294, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=5, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=5, score=0.8181818181818182, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=10, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=10, score=0.8970588235294118, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=10, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=15, score=0.9411764705882353, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=15, score=0.8529411764705882, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=15, score=0.8636363636363636, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=20, score=0.9411764705882353, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=20, score=0.8676470588235294, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=sqrt, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=sqrt, n_estimators=20, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=1, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=1, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=1 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=1, score=0.7424242424242424, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=5, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=5, score=0.8088235294117647, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=5 ............\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=5, score=0.8787878787878788, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=10, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=10, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=10 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=10, score=0.8939393939393939, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=15, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=15, score=0.8823529411764706, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=15 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=15, score=0.9242424242424242, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=20, score=0.9117647058823529, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=20, score=0.9264705882352942, total=   0.0s\n",
      "[CV] criterion=entropy, max_features=log2, n_estimators=20 ...........\n",
      "[CV]  criterion=entropy, max_features=log2, n_estimators=20, score=0.8939393939393939, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['auto', 'sqrt', 'log2'], 'criterion': ['gini', 'entropy'], 'n_estimators': [1, 5, 10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fiting our model based on the hyper-parametres and the classifier selected\n",
    "grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 15}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best hyper-parametres for our model depening upon the dataset\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_prediction = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 1.000\n",
      "Accuracy on the test subset: 0.902\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the training subset: {:.3f}'.format(grid.score(X_train, Y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(grid.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1]\n",
      " [ 4  4]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,g_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.81818182,  0.81818182,  0.72727273,  0.77777778,  0.88888889])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "etr_cv = ExtraTreesClassifier()\n",
    "scores = cross_val_score(etr_cv, X_test, Y_test, cv = 5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80606060606060603"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "etr_rfecv = ExtraTreesClassifier() \n",
    "rfecv = RFECV(estimator=etr_rfecv, step=1, cv=8, scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(X_train_scaled, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 32\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features :', rfecv.n_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features : Index(['CODE_A', 'TIME_A', 'TIME_B', 'RADIUS', 'TEXTURE', 'PERIMETR', 'AREA',\n",
      "       'SMOOTH', 'COMPCT', 'CONCV', 'SYMM', 'FRACT_D', 'SRADIUS', 'STEXTURE',\n",
      "       'SPERIMET', 'SSMOOTH', 'SCOMPCT', 'SCONCV', 'SSYMM', 'SFRACT_D',\n",
      "       'WRADIUS', 'WTEXTURE', 'WAREA', 'WSMOOTH', 'WCOMPCT', 'WCONV_PT',\n",
      "       'WSYMM', 'WFRACT_D', 'SIZE', 'NODE_ALL', 'CHEMO', 'HORMO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Best features :', X_train_scaled.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfecv_prediction = rfecv.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training subset: 1.000\n",
      "Accuracy on the test subset: 0.882\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on the training subset: {:.3f}'.format(rfecv.score(X_train_scaled, Y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(rfecv.score(X_test_scaled, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  3]\n",
      " [ 2  6]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,rfecv_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased True Negatives : 7\n",
    "\n",
    "### Evaluation using roc score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled ETR AUC:  0.675872093023\n"
     ]
    }
   ],
   "source": [
    "log_roc_auc = roc_auc_score(Y_test, etr.predict(X_test))\n",
    "print (\"Unscaled ETR AUC: \", log_roc_auc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test, etr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAHwCAYAAAD98PjEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf8LiORGq3CnYe8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a86257710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(fpr, tpr, label =\"Unscaled (area = %0.2f)\" % log_roc_auc, color =\"blue\")\n",
    "plt.plot([0,1],[0,1], 'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('Receiver operating characteristic - ExtraTreeClassifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
